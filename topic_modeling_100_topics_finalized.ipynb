{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#NCSES-class---FedRePORTER-and-IPEDS-data\" data-toc-modified-id=\"NCSES-class---FedRePORTER-and-IPEDS-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>NCSES class - FedRePORTER and IPEDS data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Python-Setup\" data-toc-modified-id=\"Python-Setup-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Python Setup</a></span></li></ul></li><li><span><a href=\"#Load-the-data\" data-toc-modified-id=\"Load-the-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Federal-RePORTER---Abstracts-(https://federalreporter.nih.gov/FileDownload)\" data-toc-modified-id=\"Federal-RePORTER---Abstracts-(https://federalreporter.nih.gov/FileDownload)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Federal RePORTER - Abstracts (<a href=\"https://federalreporter.nih.gov/FileDownload\" target=\"_blank\">https://federalreporter.nih.gov/FileDownload</a>)</a></span></li><li><span><a href=\"#NMF-method---Non-negative-matrix-factorization\" data-toc-modified-id=\"NMF-method---Non-negative-matrix-factorization-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>NMF method - Non-negative matrix factorization</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NCSES class - FedRePORTER and IPEDS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Federal RePORTER** (https://federalreporter.nih.gov) - a collaborative effort led by STAR METRICSÂ® to create a searchable database of scientific awards from agencies (across agencies or fiscal years, by the award's project leader, or by a text search of a project's title, terms, or abstracts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:34:31.689186Z",
     "start_time": "2019-08-20T13:34:29.457033Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Reading in files\n",
    "import glob\n",
    "\n",
    "# Text analysis (topic modeling)\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federal RePORTER - Abstracts (https://federalreporter.nih.gov/FileDownload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:34:43.943435Z",
     "start_time": "2019-08-20T13:34:43.935241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FedRePORTER_PRJABS_C_FY2009.csv', 'FedRePORTER_PRJABS_C_FY2008.csv', 'FedRePORTER_PRJABS_C_FY2018.csv', 'FedRePORTER_PRJABS_C_FY2017.csv', 'FedRePORTER_PRJABS_C_FY2003.csv', 'FedRePORTER_PRJABS_C_FY2002.csv', 'FedRePORTER_PRJABS_C_FY2016.csv', 'FedRePORTER_PRJABS_C_FY2000.csv', 'FedRePORTER_PRJABS_C_FY2014.csv', 'FedRePORTER_PRJABS_C_FY2015.csv', 'FedRePORTER_PRJABS_C_FY2001.csv', 'FedRePORTER_PRJABS_C_FY2005.csv', 'FedRePORTER_PRJABS_C_FY2011.csv', 'FedRePORTER_PRJABS_C_FY2010.csv', 'FedRePORTER_PRJABS_C_FY2004.csv', 'FedRePORTER_PRJABS_C_FY2012.csv', 'FedRePORTER_PRJABS_C_FY2006.csv', 'FedRePORTER_PRJABS_C_FY2007.csv', 'FedRePORTER_PRJABS_C_FY2013.csv']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get all files with project abstracts.\"\"\"\n",
    "\n",
    "abstracts_files = glob.glob('FedRePORTER_PRJABS_C_FY20*.csv')\n",
    "print(abstracts_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:35:13.431283Z",
     "start_time": "2019-08-20T13:34:44.524344Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Read them in, concatenate and convert to a dataframe.\"\"\"\n",
    "\n",
    "list_data = []\n",
    "for filename in abstracts_files:\n",
    "    data = pd.read_csv(filename)\n",
    "    list_data.append(data)\n",
    "    \n",
    "abstracts = pd.concat(list_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:35:14.111436Z",
     "start_time": "2019-08-20T13:35:13.643140Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Drop missing abstracts.\"\"\"\n",
    "\n",
    "abstracts = abstracts.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:35:14.511156Z",
     "start_time": "2019-08-20T13:35:14.444892Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Get abstracts as a list to feed in to TfidfVectorizer in the next step.\"\"\"\n",
    "\n",
    "merged_abstracts_list = abstracts[' ABSTRACT'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF method - Non-negative matrix factorization\n",
    "\n",
    "NMF is a model used for topic extraction - while the LDA model uses raw counts of unique words per document, NMF model uses a normalized representation of those raw counts (TF-IDF representation)\n",
    "\n",
    "TF stands for term-frequency and TF-IDF is term-frequency times inverse document-frequency. In other words, we are not only looking for how often a word appears in a given document, but also whether this particular word is distinct across all the collections of documents (corpus). For example, intuitively we understand that words like \"often\" or \"use\" are more frequently encountered, but they are less informative (more semantically-vacuous) if we want to discern a particular topic of a document, as they might be frequently encounter across all text documents in a corpus. On the other hand, words which we will see less frequently across a collection of document might indicate that those words are specific to a particular document, and, therefore, constitute a basis for a topic. \n",
    "\n",
    "More here: \n",
    "\n",
    "- https://scikit-learn.org/stable/modules/decomposition.html#non-negative-matrix-factorization-nmf-or-nnmf\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Convert a collection of raw documents to a matrix of TF-IDF features.\"\"\"\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf = vectorizer.fit_transform(merged_abstracts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get feature names.\"\"\"\n",
    "\n",
    "vectorizer_feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run the model with 100 topics.\"\"\"\n",
    "\n",
    "nmf = NMF(n_components=100, verbose=2).fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:45:00.847041Z",
     "start_time": "2019-08-20T13:42:42.385559Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"View the list of topics (10 top words per topic)\"\"\"\n",
    "\n",
    "for topic_idx, topic in enumerate(nmf_H):\n",
    "    print(\"Topic %d:\" % (topic_idx))\n",
    "    print('----------------------------')\n",
    "    print(\" \".join([vectorizer_feature_names[i]\n",
    "                for i in topic.argsort()[:-10 - 1:-1]]))\n",
    "    print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"View a top document related to a given topic\"\"\"\n",
    "\n",
    "for topic_idx, topic in enumerate(nmf_H):\n",
    "    print('--------------------')\n",
    "    print(\"Topic %d:\" % (topic_idx))\n",
    "    print('--------------------')\n",
    "    print(\" \".join([vectorizer_feature_names[i]\n",
    "                    for i in topic.argsort()[:-10 - 1:-1]]))\n",
    "    top_doc_indices = np.argsort(nmf_W[:,topic_idx] )[::-1][0:1]\n",
    "    for doc_index in top_doc_indices:\n",
    "        print('--------------------')\n",
    "        print(filtered_abstracts[doc_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of the first topic model with 100 topics, 2 topics related to opioids and drug abuse are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T20:16:31.396375Z",
     "start_time": "2019-08-19T20:16:26.586333Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Get topic weights per document.\"\"\"\n",
    "\n",
    "nmf_W = nmf.transform(tfidf) \n",
    "\n",
    "topics_weights = []\n",
    "for index,i in enumerate(nmf_W): # for every document\n",
    "    topics_weights.append([index, i[25], i[57]]) # get topic weights for 2 opioid- and drug abuse-related topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T20:17:04.471628Z",
     "start_time": "2019-08-19T20:17:04.025989Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Get those abstracts which have at least some value (not zero) for either of 2 topics.\"\"\"\n",
    "\n",
    "topics_list_dataframe = pd.DataFrame(topics_weights)\n",
    "\n",
    "abstracts = abstracts.reset_index()\n",
    "topics_list_dataframe = topics_list_dataframe.rename(columns={0:'index'})\n",
    "concat = pd.concat([abstracts,topics_list_dataframe],axis=1)\n",
    "\n",
    "filtered = concat[(concat[1] != 0) | (concat[2] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:41:07.974310Z",
     "start_time": "2019-08-20T13:41:07.057704Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Get a list of abstracts from the filtered dataframe above.\"\"\"\n",
    "\n",
    "filtered_abstracts = filtered[' ABSTRACT'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T13:41:44.032056Z",
     "start_time": "2019-08-20T13:41:43.997088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416312"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run another topic model with 100 topics on the filtered abstracts.\"\"\"\n",
    "\n",
    "\"\"\"Convert a collection of raw documents to a matrix of TF-IDF features.\"\"\"\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf = vectorizer.fit_transform(filtered_abstracts)\n",
    "\n",
    "\"\"\"Get feature names\"\"\"\n",
    "vectorizer_feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "\"\"\"Run the model with 100 topics\"\"\"\n",
    "nmf = NMF(n_components=100, verbose=2).fit(tfidf)\n",
    "\n",
    "\"\"\"View the list of topics (10 top words per topic)\"\"\"\n",
    "\n",
    "for topic_idx, topic in enumerate(nmf_H):\n",
    "    print(\"Topic %d:\" % (topic_idx))\n",
    "    print('----------------------------')\n",
    "    print(\" \".join([vectorizer_feature_names[i]\n",
    "                for i in topic.argsort()[:-10 - 1:-1]]))\n",
    "    print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"View a top document related to a given topic\"\"\"\n",
    "\n",
    "for topic_idx, topic in enumerate(nmf_H):\n",
    "    print('--------------------')\n",
    "    print(\"Topic %d:\" % (topic_idx))\n",
    "    print('--------------------')\n",
    "    print(\" \".join([vectorizer_feature_names[i]\n",
    "                    for i in topic.argsort()[:-10 - 1:-1]]))\n",
    "    top_doc_indices = np.argsort(nmf_W[:,topic_idx] )[::-1][0:1]\n",
    "    for doc_index in top_doc_indices:\n",
    "        print('--------------------')\n",
    "        print(filtered_abstracts[doc_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 related topics are found in a second round of a topic model with 100 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get abstracts with 4 related topics.\"\"\"\n",
    "\n",
    "topics_weights = []\n",
    "for index,i in enumerate(nmf_W): # for every document\n",
    "    topics_weights.append([index, i[11], i[25], i[32], i[43]]) # get topic weights for 4 related topics\n",
    "\n",
    "topics_weights_dataframe = pd.DataFrame(topics_weights)\n",
    "\n",
    "\"\"\"Sum the weights for all 4 related topics per document.\"\"\"\n",
    "\n",
    "topics_weights_dataframe['sum'] = topics_weights_dataframe[1] + topics_weights_dataframe[2] + topics_weights_dataframe[3] + topics_weights_dataframe[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Filter by those abstracts who have a summed value of more than 0.01.\"\"\"\n",
    "\n",
    "filtered_by_threshold = topics_weights_dataframe[topics_weights_dataframe['sum'] >= 0.01]\n",
    "\n",
    "\"\"\"Merge with the original dataframe. Make sure that level_0 column is in both dataframes to merge on.\"\"\"\n",
    "\n",
    "filtered_abstracts = filtered_abstracts.reset_index()\n",
    "filtered_by_threshold = filtered_by_threshold.rename(columns={0:'level_0'})\n",
    "filtered_by_threshold_finalized = filtered_by_threshold.merge(filtered_abstracts,on='level_0')\n",
    "\n",
    "filtered_by_threshold_updated = filtered_by_threshold_finalized[['PROJECT_ID',' ABSTRACT']]\n",
    "\n",
    "\"\"\"Export results to .CSV\"\"\"\n",
    "\n",
    "filtered_by_threshold_updated.to_csv('Filtered_Results_Abstracts.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
